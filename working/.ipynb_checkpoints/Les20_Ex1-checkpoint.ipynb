{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b351c579",
   "metadata": {},
   "source": [
    "## Lesson 20:\n",
    "### Exercise 1: Can a computer learn if we're going to detect gravitational waves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074e8d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolofiaba/.local/lib/python3.10/site-packages/astroML/linear_model/linear_regression_errors.py:10: UserWarning: LinearRegressionwithErrors requires PyMC3 to be installed\n",
      "  warnings.warn('LinearRegressionwithErrors requires PyMC3 to be installed')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "c = sns.color_palette('Paired', 7)\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "\n",
    "if \"setup_text_plots\" not in globals():\n",
    "    from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=10, usetex=False)\n",
    "\n",
    "#------------------- Function to read the data -------------------\n",
    "def Dataframe(namefile):                                        #-\n",
    "    df = pd.read_csv(namefile, sep=',', skipinitialspace=True)  #-\n",
    "    return df                                                   #-\n",
    "#-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcbd232",
   "metadata": {},
   "source": [
    "Our goal is to classify the sources in the following dataset according to their **detectability**. The `det` feature is containing the labels for each source.\n",
    "- **0 = not detectable**\n",
    "- **1 = detectable**\n",
    "\n",
    "We want to train a classifier in order to separate sources that are detectables from those that aren't.\n",
    "\n",
    "Let's load the dataset first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8c7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b960368e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_df = pd.read_hdf(\\'sample_2e7_design_precessing_higherordermodes_3detectors.h5\\')\\n\\npickle_path = \"data.pickle\"  # Path to save the pickle file\\ndata_df.to_pickle(pickle_path)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Execute this the first time. It generates a dataframe from the h5 file and save it in a pickle file you can load later\n",
    "\"\"\"\n",
    "data_df = pd.read_hdf('sample_2e7_design_precessing_higherordermodes_3detectors.h5')\n",
    "\n",
    "pickle_path = \"data.pickle\"  # Path to save the pickle file\n",
    "data_df.to_pickle(pickle_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03bb1d4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     df \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.pickle'"
     ]
    }
   ],
   "source": [
    "with open('data.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970b37f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773c329",
   "metadata": {},
   "source": [
    "For debugging purposes let's define a downsampled dataset `df_small` with the first 5000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2a5f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_small = df.iloc[:100000]\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522734aa",
   "metadata": {},
   "source": [
    "Let's define a **training** and a **test** sub-dataframe in order to validate the performance of our classifier on unseen data (classification error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_small, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bd0fb",
   "metadata": {},
   "source": [
    "We choose to use a **Random Forest Classifier**. This is based on multiple decision trees. For each of those, at each step, the dimension in the parameter space in which to \"cut\" is selected randomly. Each decision tree votes at the end for the final classification. Our dataset is highly multi-dimensional, thus the choice of this particular classifier.\n",
    "\n",
    "**RandomForestClassifier** is implemented in *scikit-learn* and it gives access to the *importances* (weights) of the features. This is useful for determining the most relevant features of the dataset, that is the dimensions in which the sources can be most easily classified.\n",
    "\n",
    "Notice that we *whiten* the data first, so that the classifier is not biased.\n",
    "\n",
    "**NB**: We fit the classifier on a dataset in which `det` and `snr` columns are removed. The **det** column is the target column, while the **snr** directly defines the target (detectability). If left in the training dataset, the **snr** column would obviously be the most relevant feature. See the next plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a792ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.scatter(df_small['snr'], df_small['mtot'], c=df_small['det'], edgecolors='none', alpha=0.3, s=7, cmap='Paired')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('$M_{tot}$')\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118ca17",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5978233",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dabe549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Prepare the data\n",
    "\n",
    "X_train = train.drop(['det', 'snr'], axis=1).values\n",
    "y_train = train['det'].values\n",
    "\n",
    "X_test = test.drop(['det', 'snr'], axis=1).values\n",
    "y_test = test['det'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Fit the Random Forest classifier and predict\n",
    "max_depth = 10\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators=10, max_depth=max_depth)\n",
    "ranfor.fit(X_scaled_train, y_train)\n",
    "\n",
    "y_pred = ranfor.predict(X_scaled_test)\n",
    "rfc_probs = ranfor.predict_proba(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "fig.subplots_adjust(bottom=0., top=0.95, hspace=0.0,\n",
    "                    left=0., right=0.95, wspace=0.02)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(200))\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(0.5))\n",
    "\n",
    "ax.set_title('True targets')\n",
    "ax.set_xlabel(r'$m_{tot}$')\n",
    "ax.set_ylabel(r'$z$')\n",
    "\n",
    "ax.scatter(test['mtot'][y_test == 0], test['z'][y_test == 0], color=c[3], s=10, \n",
    "           edgecolors='none', alpha=0.3, label='Not detectable')\n",
    "\n",
    "ax.scatter(test['mtot'][y_test == 1], test['z'][y_test == 1], color=c[5], s=10, \n",
    "           edgecolors='none', alpha=0.3, label='Detectable')\n",
    "ax.legend(loc='upper left', framealpha=1, fancybox=False)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "ax.set_title('RFC Predictions')\n",
    "ax.set_xlabel(r'$m_{tot}$')\n",
    "\n",
    "ax.scatter(test['mtot'][y_pred == 0], test['z'][y_pred == 0], color=c[3], s=10, \n",
    "           edgecolors='none', alpha=0.3, label='Not detectable')\n",
    "\n",
    "ax.scatter(test['mtot'][y_pred == 1], test['z'][y_pred == 1], color=c[5], s=10, \n",
    "           edgecolors='none', alpha=0.3, label='Detectable')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f03703",
   "metadata": {},
   "source": [
    "Now we can see which features are the most relevant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a2023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names = df_small.drop(['det', 'snr'], axis=1).columns.tolist()\n",
    "\n",
    "dict(zip(column_names, ranfor.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cfdba2",
   "metadata": {},
   "source": [
    "The most relevant features are the *redshift* `z` (83% importance) and the *total mass* `mtot` (4% importance).\n",
    "\n",
    "Now let's evaluate the performance of the classifier on the **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from astroML.utils import completeness_contamination\n",
    "\n",
    "print(\"The accuracy of the Random Forest Classifier is\", accuracy_score(y_test, y_pred)*100, '%')\n",
    "\n",
    "completeness, contamination = completeness_contamination(y_pred, y_test)\n",
    "\n",
    "print(\"Completeness and contamination are:\\n\\t\", completeness*100, \"%\\n\\t\", contamination*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e04916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "positive_prob = rfc_probs[:,1] # 1: Detectable sources\n",
    "fpr, tpr, thresholds = roc_curve(y_test, positive_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e35a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "ax = plt.subplot(111)\n",
    "ax.plot([0,1], [0,1], '--k', label='random guess')\n",
    "\n",
    "ax.plot(fpr, tpr, ls='-', lw=2., c=c[5], label=r'ROC curve')\n",
    "\n",
    "ax.fill_between(fpr, tpr, color=c[5], alpha=0.1)\n",
    "    \n",
    "ax.set_xlabel('fpr');\n",
    "ax.set_ylabel('tpr');\n",
    "ax.legend(loc='lower right', frameon=False);\n",
    "ax.set_title(f'ROC curve - Random Forest Classifier \\n Maximum Depth = %i'%max_depth);\n",
    "\n",
    "ax.grid(True, ls='--', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e3e36",
   "metadata": {},
   "source": [
    "Notice that changing the value of `max_depth` in the definition of the classifier is changing the final accuracy score. We can cross validate it by using *GridSearchCV*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1619d19",
   "metadata": {},
   "source": [
    "### Maximum depth cross validation\n",
    "- With *GridSearchCV* it takes about 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depth_range = np.linspace(1 ,1000, 11, dtype=int)\n",
    "\n",
    "K = 5 # 5-fold cross validation\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), {'max_depth': depth_range}, cv = K, n_jobs=-1) \n",
    "grid.fit(X_scaled_train, y_train)\n",
    "depth_opt = grid.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f91875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The optimal maximum depth is\", depth_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e04d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranfor = RandomForestClassifier(n_estimators=10, max_depth=depth_opt)\n",
    "ranfor.fit(X_scaled_train, y_train)\n",
    "\n",
    "y_pred = ranfor.predict(X_scaled_test)\n",
    "\n",
    "print(\"The accuracy of the Random Forest Classifier, with optimal maximum depth, is\", \n",
    "      accuracy_score(y_test, y_pred)*100, '%')\n",
    "\n",
    "completeness, contamination = completeness_contamination(y_pred, y_test)\n",
    "\n",
    "print(\"Completeness and contamination are:\\n\\t\", completeness*100, \"%\\n\\t\", contamination*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b168e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
